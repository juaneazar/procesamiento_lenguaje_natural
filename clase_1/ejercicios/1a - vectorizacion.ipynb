{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[],"source":["# Separo cada documento\n","documento_1 = corpus[0]\n","documento_2 = corpus[1]\n","documento_3 = corpus[2]\n","\n","# Separo cada documento en una lista de términos\n","documento_1_sep = np.array(documento_1.split())\n","documento_2_sep = np.array(documento_2.split())\n","documento_3_sep = np.array(documento_3.split())\n","\n","# Sin repetirse\n","documento_1_norep = np.unique(documento_1_sep)\n","documento_2_norep = np.unique(documento_2_sep)\n","documento_3_norep = np.unique(documento_3_sep)"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que'] \n","\n","[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n"," [1. 1. 1. 1. 0. 1. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n"]}],"source":["# Obtengo todas las palabras sin repetirse de los tres documentos\n","palabras = np.unique(np.concatenate([doc.split() for doc in corpus]))\n","\n","print(palabras,'\\n')\n","\n","# Creo una matriz de ceros de la forma  n_documentos x n_palabras_únicas\n","n_documentos = len(corpus)\n","n_palabras_únicas = len(palabras)\n","matriz = np.zeros((n_documentos, n_palabras_únicas))\n","\n","# Lleno la matriz con unos y ceros para indicar la presencia o ausencia de cada palabra\n","for i, doc in enumerate(corpus):\n","    palabras_documento = doc.split()\n","    for j, palabra in enumerate(palabras):\n","        if palabra in palabras_documento:\n","            matriz[i, j] = 1\n","print(matriz)"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n"," [1. 1. 1. 1. 0. 1. 2. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n"]}],"source":["# Creo otra matriz de ceros de la misma dimensión \n","matriz2 = np.zeros((n_documentos, n_palabras_únicas))\n","\n","# Lleno la matriz con la cantidad de veces que aparece cada palabra en cada documento\n","for i, doc in enumerate(corpus):\n","    palabras_documento = doc.split()\n","    for j, palabra in enumerate(palabras):\n","        matriz2[i, j] = palabras_documento.count(palabra)\n","\n","# Mostrar la matriz de documentos con recuentos de palabras\n","print(matriz2)"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","2\n","1\n","2\n","1\n","2\n","2\n","1\n","1\n","Matriz TF:\n","  [[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n"," [1. 1. 1. 1. 0. 1. 2. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 1. 1. 0.]] \n","\n","Matriz IDF:\n"," [0.47712125 0.17609126 0.47712125 0.17609126 0.47712125 0.17609126\n"," 0.17609126 0.47712125 0.47712125] \n","\n","Matriz TFIDF: \n"," [[0.         0.17609126 0.         0.17609126 0.         0.17609126\n","  0.         0.         0.47712125]\n"," [0.47712125 0.17609126 0.47712125 0.17609126 0.         0.17609126\n","  0.35218252 0.         0.        ]\n"," [0.         0.         0.         0.         0.47712125 0.\n","  0.17609126 0.47712125 0.        ]] \n","\n"]}],"source":["# Utilizo la matriz TF calculada en el inciso anterior\n","# Calculo la matriz de frecuencia inversa IDF\n","matriz_idf = np.zeros(n_palabras_únicas)\n","for j, palabra in enumerate(palabras):\n","    n_documentos_con_palabra = np.sum(matriz2[:, j] > 0)\n","    print(n_documentos_con_palabra)\n","    if n_documentos_con_palabra > 0:\n","        matriz_idf[j] = np.log10(n_documentos / n_documentos_con_palabra)\n","\n","# Calculo la TF-IDF multiplicando TF por IDF\n","matriz_tfidf = matriz2 * matriz_idf\n","\n","print('Matriz TF:\\n ',matriz2,'\\n')\n","\n","print('Matriz IDF:\\n',matriz_idf,'\\n')\n","\n","print('Matriz TFIDF: \\n',matriz_tfidf,'\\n')"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":["# Para no desordenar lo realizado anteriormente, voy a utilizar la función que nos brindan al principio del enunciado \n","# y voy a pasarle como argumentos entrada la matriz TFIDF del corpus ya procesado y el corpus(para ordenarlo).\n","def ordenar(corpus_a_ordenar,m_tfidf):\n","    similitud=cosine_similarity(m_tfidf,m_tfidf.T)\n","    print(\"Similitud:\\n\",similitud)\n","    indices_ordenados = np.argsort(np.diagonal(similitud))\n","    return corpus_a_ordenar[indices_ordenados]"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Similitud:\n"," [[0.21676894 0.06288351 0.        ]\n"," [0.06288351 0.45449905 0.04192234]\n"," [0.         0.04192234 0.32873202]]\n","\n"," \n","Corpus ordenado por similitud de menor a mayor: \n","que dia es hoy\n","martes muchas gracias\n","martes el dia de hoy es martes\n"]}],"source":["corpus_ordenado=ordenar(corpus,matriz_tfidf)\n","print(\"\\n \\nCorpus ordenado por similitud de menor a mayor: \")\n","for doc in corpus_ordenado:\n","    print(doc)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
