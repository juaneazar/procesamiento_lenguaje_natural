{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM Bot QA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### Datos\n",
        "El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n",
        "[LINK](http://convai.io/data/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 8000\n",
        "MAX_LENGTH = 10\n",
        "N_UNITS = 128\n",
        "EPOCHS = 40\n",
        "LSTM_DROPOUT = 0.2"
      ],
      "metadata": {
        "id": "aCXxX8cFHm8z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bDFC0I3j9oFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fdeb0e-6bc2-4d6b-a4ac-f4d23a0b77bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet\n",
        "!pip install --upgrade tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM, SimpleRNN\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.utils import plot_model\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RHNkUaPp6aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ed05bb-b0b9-426d-8ca8-484b1d7b5b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El dataset ya se encuentra descargado\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import gdown\n",
        "if os.access('data_volunteers.json', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
        "    output = 'data_volunteers.json'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WZy1-wgG-Rp7"
      },
      "outputs": [],
      "source": [
        "# dataset_file\n",
        "import json\n",
        "\n",
        "text_file = \"data_volunteers.json\"\n",
        "with open(text_file) as f:\n",
        "    data = json.load(f) # la variable data será un diccionario\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ue5qd54S-eew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859bcf9c-4a7f-494b-e5b3-95e63a8bb980"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Observar los campos disponibles en cada linea del dataset\n",
        "data[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jHBRAXPl-3dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7cb2225-217a-4ce4-8c90-4f7f409260fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows utilizadas: 6033\n"
          ]
        }
      ],
      "source": [
        "chat_in = []\n",
        "chat_out = []\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "max_len = 30\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt.replace(\"\\'d\", \" had\")\n",
        "    txt.replace(\"\\'s\", \" is\")\n",
        "    txt.replace(\"\\'m\", \" am\")\n",
        "    txt.replace(\"don't\", \"do not\")\n",
        "    txt = re.sub(r'\\W+', ' ', txt)\n",
        "\n",
        "    return txt\n",
        "\n",
        "for line in data:\n",
        "    for i in range(len(line['dialog'])-1):\n",
        "        # vamos separando el texto en \"preguntas\" (chat_in)\n",
        "        # y \"respuestas\" (chat_out)\n",
        "        chat_in = clean_text(line['dialog'][i]['text'])\n",
        "        chat_out = clean_text(line['dialog'][i+1]['text'])\n",
        "\n",
        "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
        "            continue\n",
        "\n",
        "        input_sentence, output = chat_in, chat_out\n",
        "\n",
        "        # output sentence (decoder_output) tiene <eos>\n",
        "        output_sentence = output + ' <eos>'\n",
        "        # output sentence input (decoder_input) tiene <sos>\n",
        "        output_sentence_input = '<sos> ' + output\n",
        "\n",
        "        input_sentences.append(input_sentence)\n",
        "        output_sentences.append(output_sentence)\n",
        "        output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "07L1qj8pC_l6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9ad7ae-0977-4dd5-d4fe-7a8daf67cd82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "input_sentences[1], output_sentences[1], output_sentences_inputs[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento\n",
        "Realizar el preprocesamiento necesario para obtener:\n",
        "- word2idx_inputs, max_input_len\n",
        "- word2idx_outputs, max_out_len, num_words_output\n",
        "- encoder_input_sequences, decoder_output_sequences, decoder_targets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada más larga:\", max_input_len)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thYGSsehB39Y",
        "outputId": "85f432fa-1ca0-4328-923c-b60871640fe1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 1799\n",
            "Sentencia de entrada más larga: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"\", \"\"] + output_sentences)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer\n",
        "print(\"Palabras de salida:\", num_words_output)\n",
        "\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida más larga:\", max_out_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsnKJT34DQOP",
        "outputId": "9207300a-04cc-40fb-84d8-905c596c2757"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 1805\n",
            "Palabras de salida: 1806\n",
            "Sentencia de salida más larga: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "EjEfFKaDM1pS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)\n",
        "\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)\n",
        "\n",
        "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
        "print(\"decoder_targets shape:\", decoder_targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2BzwfB-MPm6",
        "outputId": "ba90e7e6-762d-4442-d2a8-0e0705294042"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input_sequences shape: (6033, 9)\n",
            "decoder_input_sequences shape: (6033, 10)\n",
            "decoder_output_sequences shape: (6033, 10)\n",
            "decoder_targets shape: (6033, 10, 1806)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### 3 - Preparar los embeddings\n",
        "Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.access('fasttext.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/u/0/uc?id=1Qi1r-u5lsEsNqRSxLrpNOqQ3B_ufltCa&export=download&confirm=t'\n",
        "    output = 'fasttext.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings de fasttext ya están descargados.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UbHMx84GyRd",
        "outputId": "b1035cf5-06e3-463b-be0a-7b0ed7856082"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los embeddings de fasttext ya están descargados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ],
      "metadata": {
        "id": "DVcTkzxHYV7Y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_embeddings = FasttextEmbeddings()\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "embed_dim = model_embeddings.N_FEATURES\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provieen del tokenizer\n",
        "\n",
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf8KkfBs7rPL",
        "outputId": "9c32ca88-4a56-4e88-cf14-73c0f7ff128a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing embedding matrix...\n",
            "number of null word embeddings: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensión de los embeddings de la secuencia en ingles\n",
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsiAYsVnGw11",
        "outputId": "32d9d4f1-e5b8-4fc4-ace7-72e1fea4e693"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1799, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo\n",
        "Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define training encoder\n",
        "encoder_inputs = Input(shape=(max_input_len))\n",
        "\n",
        "encoder_embedding_layer = Embedding(\n",
        "    input_dim=nb_words,\n",
        "    output_dim=embed_dim,\n",
        "    input_length=max_input_len,\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=False)\n",
        "\n",
        "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
        "\n",
        "encoder = LSTM(N_UNITS,\n",
        "               return_state=True,\n",
        "               dropout=LSTM_DROPOUT,\n",
        "               )\n",
        "\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# define training decoder\n",
        "decoder_inputs = Input(shape=(max_out_len))\n",
        "decoder_embedding_layer = Embedding(\n",
        "    input_dim=num_words_output,\n",
        "    output_dim=N_UNITS,\n",
        "    input_length=max_out_len)\n",
        "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(N_UNITS,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=LSTM_DROPOUT,\n",
        "                    )\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
        "\n",
        "# Dense\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t1GaNLkLbUP",
        "outputId": "8b94383b-c6b6-4ac8-fb9c-1939cb0d2f40"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 9)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 10)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 9, 300)               539700    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 10, 128)              231168    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 128),                219648    ['embedding[0][0]']           \n",
            "                              (None, 128),                                                        \n",
            "                              (None, 128)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, 10, 128),            131584    ['embedding_1[0][0]',         \n",
            "                              (None, 128),                           'lstm[0][1]',                \n",
            "                              (None, 128)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10, 1806)             232974    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1355074 (5.17 MB)\n",
            "Trainable params: 815374 (3.11 MB)\n",
            "Non-trainable params: 539700 (2.06 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "vkUmq2qWLzGe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_state_input_h = Input(shape=(N_UNITS,))\n",
        "decoder_state_input_c = Input(shape=(N_UNITS,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n"
      ],
      "metadata": {
        "id": "BRC_cdFnL4rO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=0.2,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIbFH91KL8TP",
        "outputId": "d36b625e-d860-443b-b0c7-5e7240644deb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "151/151 [==============================] - 15s 43ms/step - loss: 3.0677 - accuracy: 0.5090 - val_loss: 2.1965 - val_accuracy: 0.6410\n",
            "Epoch 2/40\n",
            "151/151 [==============================] - 2s 14ms/step - loss: 1.8199 - accuracy: 0.6804 - val_loss: 1.6849 - val_accuracy: 0.7181\n",
            "Epoch 3/40\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 1.3397 - accuracy: 0.7752 - val_loss: 1.3417 - val_accuracy: 0.7936\n",
            "Epoch 4/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0374 - accuracy: 0.8280 - val_loss: 1.1243 - val_accuracy: 0.8355\n",
            "Epoch 5/40\n",
            "151/151 [==============================] - 2s 14ms/step - loss: 0.8427 - accuracy: 0.8690 - val_loss: 0.9757 - val_accuracy: 0.8664\n",
            "Epoch 6/40\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 0.7055 - accuracy: 0.8942 - val_loss: 0.8672 - val_accuracy: 0.8858\n",
            "Epoch 7/40\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 0.6061 - accuracy: 0.9116 - val_loss: 0.7912 - val_accuracy: 0.8963\n",
            "Epoch 8/40\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.5321 - accuracy: 0.9217 - val_loss: 0.7327 - val_accuracy: 0.9075\n",
            "Epoch 9/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.4736 - accuracy: 0.9306 - val_loss: 0.6870 - val_accuracy: 0.9172\n",
            "Epoch 10/40\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.4253 - accuracy: 0.9384 - val_loss: 0.6505 - val_accuracy: 0.9239\n",
            "Epoch 11/40\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.3838 - accuracy: 0.9440 - val_loss: 0.6196 - val_accuracy: 0.9283\n",
            "Epoch 12/40\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.3476 - accuracy: 0.9493 - val_loss: 0.5952 - val_accuracy: 0.9342\n",
            "Epoch 13/40\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.3153 - accuracy: 0.9540 - val_loss: 0.5733 - val_accuracy: 0.9401\n",
            "Epoch 14/40\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 0.2867 - accuracy: 0.9586 - val_loss: 0.5552 - val_accuracy: 0.9420\n",
            "Epoch 15/40\n",
            "151/151 [==============================] - 2s 16ms/step - loss: 0.2607 - accuracy: 0.9623 - val_loss: 0.5389 - val_accuracy: 0.9447\n",
            "Epoch 16/40\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.2371 - accuracy: 0.9654 - val_loss: 0.5240 - val_accuracy: 0.9471\n",
            "Epoch 17/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.2156 - accuracy: 0.9678 - val_loss: 0.5124 - val_accuracy: 0.9495\n",
            "Epoch 18/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.1959 - accuracy: 0.9706 - val_loss: 0.4993 - val_accuracy: 0.9516\n",
            "Epoch 19/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.1775 - accuracy: 0.9730 - val_loss: 0.4898 - val_accuracy: 0.9537\n",
            "Epoch 20/40\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.1605 - accuracy: 0.9753 - val_loss: 0.4778 - val_accuracy: 0.9563\n",
            "Epoch 21/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.1446 - accuracy: 0.9774 - val_loss: 0.4683 - val_accuracy: 0.9588\n",
            "Epoch 22/40\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.1296 - accuracy: 0.9797 - val_loss: 0.4583 - val_accuracy: 0.9598\n",
            "Epoch 23/40\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 0.1158 - accuracy: 0.9814 - val_loss: 0.4496 - val_accuracy: 0.9615\n",
            "Epoch 24/40\n",
            "151/151 [==============================] - 2s 14ms/step - loss: 0.1028 - accuracy: 0.9839 - val_loss: 0.4395 - val_accuracy: 0.9626\n",
            "Epoch 25/40\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 0.0907 - accuracy: 0.9872 - val_loss: 0.4311 - val_accuracy: 0.9639\n",
            "Epoch 26/40\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.0793 - accuracy: 0.9907 - val_loss: 0.4222 - val_accuracy: 0.9650\n",
            "Epoch 27/40\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.0691 - accuracy: 0.9938 - val_loss: 0.4150 - val_accuracy: 0.9658\n",
            "Epoch 28/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.0594 - accuracy: 0.9964 - val_loss: 0.4064 - val_accuracy: 0.9662\n",
            "Epoch 29/40\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.0507 - accuracy: 0.9982 - val_loss: 0.4003 - val_accuracy: 0.9674\n",
            "Epoch 30/40\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 0.0430 - accuracy: 0.9990 - val_loss: 0.3921 - val_accuracy: 0.9675\n",
            "Epoch 31/40\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 0.0360 - accuracy: 0.9995 - val_loss: 0.3858 - val_accuracy: 0.9683\n",
            "Epoch 32/40\n",
            "151/151 [==============================] - 2s 14ms/step - loss: 0.0300 - accuracy: 0.9997 - val_loss: 0.3790 - val_accuracy: 0.9686\n",
            "Epoch 33/40\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.0250 - accuracy: 0.9999 - val_loss: 0.3727 - val_accuracy: 0.9692\n",
            "Epoch 34/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9694\n",
            "Epoch 35/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9696\n",
            "Epoch 36/40\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9701\n",
            "Epoch 37/40\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9704\n",
            "Epoch 38/40\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9706\n",
            "Epoch 39/40\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9706\n",
            "Epoch 40/40\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vT6KeM1rOG0Q",
        "outputId": "61ff2a43-929c-4076-c405-4a21cd2b50bb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia\n",
        "Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Armar lo conversores de indice a palabra:\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "metadata": {
        "id": "V3A2jV6nPiPG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_prompt(input_seq):\n",
        "    # Obtener los estados internos del modelo del codificador\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Inicializar la secuencia de destino con un token vacío\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['']\n",
        "\n",
        "    # Obtener el índice del token de final de oración\n",
        "    eos = word2idx_outputs['']\n",
        "\n",
        "    # Inicializar una lista para almacenar la traducción de salida\n",
        "    output_sentence = []\n",
        "\n",
        "    # Generar la secuencia de salida\n",
        "    for _ in range(max_out_len):\n",
        "        # Predecir los tokens de salida y los estados internos del modelo del decodificador\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Encontrar el índice del token con la probabilidad más alta\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        # Comprobar si el token predicho es un token de final de oración\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "        if idx > 0:\n",
        "            # Obtener la palabra correspondiente al índice predicho\n",
        "            word = idx2word_target[idx]\n",
        "            # Agregar la palabra a la traducción de salida\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        # Actualizar los estados internos para la siguiente iteración\n",
        "        states_value = [h, c]\n",
        "        # Establecer el token predicho como entrada para la siguiente iteración\n",
        "        target_seq[0, 0] = idx\n",
        "\n",
        "    # Devolver la traducción de salida como una cadena\n",
        "    return ' '.join(output_sentence)\n"
      ],
      "metadata": {
        "id": "TCbQqWFbRdIT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test = \"Do you read?\"\n",
        "print('Input:', input_test)\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "print('Input:', input_test)\n",
        "translation = answer_prompt(encoder_sequence_test)\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Pqt8fTYHxgie",
        "outputId": "4fefb749-2754-424f-de7b-8d2ce47442ce"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Do you read?\n",
            "Representacion en vector de tokens de ids [3, 2, 23]\n",
            "Padding del vector: [[ 0  0  0  0  0  0  3  2 23]]\n",
            "Input: Do you read?\n",
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e229ac47d948>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_sequence_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Response:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-85d726cd7ea2>\u001b[0m in \u001b[0;36manswer_prompt\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Inicializar la secuencia de destino con un token vacío\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Obtener el índice del token de final de oración\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ''"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test = 'Do you have any pet?'\n",
        "print('Input:', input_test)\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "print('Input:', input_test)\n",
        "translation = answer_prompt(encoder_sequence_test)\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "P4GPQAe7zEkE",
        "outputId": "4ae117ff-a520-48b5-95a0-8b18247eded3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Do you have any pet?\n",
            "Representacion en vector de tokens de ids [3, 2, 16, 31, 252]\n",
            "Padding del vector: [[  0   0   0   0   3   2  16  31 252]]\n",
            "Input: Do you have any pet?\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-669720988275>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_sequence_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Response:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-485c8e3a0fbf>\u001b[0m in \u001b[0;36manswer_prompt\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0meos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ''"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_test = 'Where are you from?'\n",
        "print('Input:', input_test)\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "print('Input:', input_test)\n",
        "translation = answer_prompt(encoder_sequence_test)\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "55mAJrINzHJu",
        "outputId": "984e1835-37fb-4674-da7a-b6a2c8ffa29c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Where are you from?\n",
            "Representacion en vector de tokens de ids [52, 7, 2, 39]\n",
            "Padding del vector: [[ 0  0  0  0  0 52  7  2 39]]\n",
            "Input: Where are you from?\n",
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-188435e6ed93>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_sequence_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Response:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-485c8e3a0fbf>\u001b[0m in \u001b[0;36manswer_prompt\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0meos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ''"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}